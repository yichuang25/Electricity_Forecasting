{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\miniconda3\\envs\\env2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "import autogluon.core as ag\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # Should be True\n",
    "print(torch.cuda.device_count())  # Should be > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>38313.751557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-02</th>\n",
       "      <td>57225.098775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-03</th>\n",
       "      <td>57294.353754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>57503.687632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>57662.515150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          target\n",
       "item_id timestamp               \n",
       "1       2012-01-01  38313.751557\n",
       "        2012-01-02  57225.098775\n",
       "        2012-01-03  57294.353754\n",
       "        2012-01-04  57503.687632\n",
       "        2012-01-05  57662.515150"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg = pd.read_pickle('../Data/ELC_12-14_1D_dropped_avg.pkl')\n",
    "\n",
    "df_avg_convert = df_avg.copy()\n",
    "df_avg_convert['id'] = 1\n",
    "df_avg_convert = df_avg_convert.rename(columns = {\"y\": \"target\"})\n",
    "df_avg_convert = TimeSeriesDataFrame.from_data_frame(\n",
    "    df_avg_convert,\n",
    "    id_column=\"id\",\n",
    "    timestamp_column=\"ds\"\n",
    ")\n",
    "\n",
    "df_avg_convert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:  (876, 1)\n",
      "validation:  (110, 1)\n",
      "testing:  (110, 1)\n"
     ]
    }
   ],
   "source": [
    "training_x = df_avg_convert.iloc[:int(len(df_avg_convert)*0.8)]\n",
    "val_x = df_avg_convert.iloc[int(len(df_avg_convert)*0.8):int(len(df_avg_convert)*0.9)]\n",
    "testing_x = df_avg_convert.iloc[int(len(df_avg_convert)*0.9):]\n",
    "print(\"training: \", training_x.shape)\n",
    "print(\"validation: \", val_x.shape)\n",
    "print(\"testing: \", testing_x.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "================ TimeSeriesPredictor ================\n",
      "TimeSeriesPredictor.fit() called\n",
      "Fitting with arguments:\n",
      "{'ag_args_fit': {'num_gpus': 1},\n",
      " 'enable_ensemble': True,\n",
      " 'evaluation_metric': 'MAPE',\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'hyperparameters': {'TemporalFusionTransformer': {}},\n",
      " 'prediction_length': 110,\n",
      " 'random_seed': None,\n",
      " 'target': 'target',\n",
      " 'time_limit': None}\n",
      "Provided training data set with 876 rows, 1 items (item = single time series). Average time series length is 876.0.\n",
      "Provided tuning data set with 110 rows, 1 items. Average time series length is 110.0.\n",
      "Training artifacts will be saved to: C:\\Users\\Alex\\OneDrive - University of Rochester\\Desktop\\2023Spring\\Forcasting\\IEOR4574-Forcasting\\Electricity_Forecasting\\Model\\AutogluonModels\\ag-20230502_022829\n",
      "=====================================================\n",
      "AutoGluon will save models to AutogluonModels\\ag-20230502_022829\\\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'\n",
      "\tThis metric's sign has been flipped to adhere to being 'higher is better'. The reported score can be multiplied by -1 to get the metric value.\n",
      "\n",
      "Provided dataset contains following columns:\n",
      "\ttarget:           'target'\n",
      "\n",
      "Starting training. Start time is 2023-05-01 22:28:29\n",
      "Models that will be trained: ['TemporalFusionTransformer']\n",
      "Training timeseries model TemporalFusionTransformer. \n",
      "\tWarning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.\n",
      "\tdivision by zero\n",
      "Not fitting ensemble as no models were successfully trained.\n",
      "Training complete. Models trained: []\n",
      "Total runtime: 409.43 s\n",
      "Trainer has no fit models that can predict.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.timeseries.predictor.TimeSeriesPredictor at 0x2432ef43c70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_TFT = TimeSeriesPredictor(prediction_length = 110, eval_metric=\"MAPE\", fast_training = True)\n",
    "\n",
    "predictor_TFT.fit(\n",
    "    training_x,\n",
    "    hyperparameters={\n",
    "        \"TemporalFusionTransformer\":{}\n",
    "    },\n",
    "    tuning_data = val_x,\n",
    "    ag_args_fit={'num_gpus': 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_25336\\1942128367.py:1: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  predictions_TFT = predictor_TFT.predict(pd.concat(training_x, val_x))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "first argument must be an iterable of pandas objects, you passed an object of type \"TimeSeriesDataFrame\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions_TFT \u001b[39m=\u001b[39m predictor_TFT\u001b[39m.\u001b[39mpredict(pd\u001b[39m.\u001b[39;49mconcat(training_x, val_x))\n\u001b[0;32m      2\u001b[0m predictions_TFT\u001b[39m.\u001b[39mhead(\u001b[39m5\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\miniconda3\\envs\\env2\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\miniconda3\\envs\\env2\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mobjs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcat\u001b[39m(\n\u001b[0;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m    159\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39m    1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m         objs,\n\u001b[0;32m    370\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    371\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[0;32m    372\u001b[0m         join\u001b[39m=\u001b[39;49mjoin,\n\u001b[0;32m    373\u001b[0m         keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[0;32m    374\u001b[0m         levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[0;32m    375\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[0;32m    376\u001b[0m         verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[0;32m    377\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    378\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    379\u001b[0m     )\n\u001b[0;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\Alex\\miniconda3\\envs\\env2\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:403\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    390\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    391\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    400\u001b[0m     sort\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    401\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(objs, (ABCSeries, ABCDataFrame, \u001b[39mstr\u001b[39m)):\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    404\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mfirst argument must be an iterable of pandas \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    405\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobjects, you passed an object of type \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(objs)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    406\u001b[0m         )\n\u001b[0;32m    408\u001b[0m     \u001b[39mif\u001b[39;00m join \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mouter\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    409\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintersect \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: first argument must be an iterable of pandas objects, you passed an object of type \"TimeSeriesDataFrame\""
     ]
    }
   ],
   "source": [
    "predictions_TFT = predictor_TFT.predict(pd.concat(training_x, val_x))\n",
    "predictions_TFT.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230502_024424\\\"\n",
      "c:\\Users\\Alex\\miniconda3\\envs\\env2\\lib\\site-packages\\autogluon\\timeseries\\predictor.py:436: UserWarning: Detected short time series in train_data. For best performance, all training time series should have length >= 2 * prediction_length + 1(at least 221).\n",
      "  warnings.warn(\n",
      "================ TimeSeriesPredictor ================\n",
      "TimeSeriesPredictor.fit() called\n",
      "Fitting with arguments:\n",
      "{'ag_args_fit': {'num_gpus': 1},\n",
      " 'enable_ensemble': True,\n",
      " 'evaluation_metric': 'MAPE',\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'hyperparameters': {'DeepAR': {}},\n",
      " 'prediction_length': 110,\n",
      " 'random_seed': None,\n",
      " 'target': 'target',\n",
      " 'time_limit': None}\n",
      "Provided training data set with 110 rows, 1 items (item = single time series). Average time series length is 110.0.\n",
      "Provided tuning data set with 110 rows, 1 items. Average time series length is 110.0.\n",
      "Training artifacts will be saved to: C:\\Users\\Alex\\OneDrive - University of Rochester\\Desktop\\2023Spring\\Forcasting\\IEOR4574-Forcasting\\Electricity_Forecasting\\Model\\AutogluonModels\\ag-20230502_024424\n",
      "=====================================================\n",
      "AutoGluon will save models to AutogluonModels\\ag-20230502_024424\\\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'\n",
      "\tThis metric's sign has been flipped to adhere to being 'higher is better'. The reported score can be multiplied by -1 to get the metric value.\n",
      "\n",
      "Provided dataset contains following columns:\n",
      "\ttarget:           'target'\n",
      "\n",
      "Starting training. Start time is 2023-05-01 22:44:24\n",
      "Models that will be trained: ['DeepAR']\n",
      "Training timeseries model DeepAR. \n",
      "\tWarning: Exception caused DeepAR to fail during training... Skipping this model.\n",
      "\tdivision by zero\n",
      "Not fitting ensemble as no models were successfully trained.\n",
      "Training complete. Models trained: []\n",
      "Total runtime: 131.84 s\n",
      "Trainer has no fit models that can predict.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.timeseries.predictor.TimeSeriesPredictor at 0x2432ef41840>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_DAR = TimeSeriesPredictor(prediction_length = 110, eval_metric=\"MAPE\", fast_training = True)\n",
    "\n",
    "predictor_DAR.fit(\n",
    "    testing_x,\n",
    "    hyperparameters={\n",
    "        \"DeepAR\":{}\n",
    "    },\n",
    "    tuning_data = val_x,\n",
    "    ag_args_fit={'num_gpus': 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
